# -*- coding: utf-8 -*-
"""CropWeed Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_37U7ZhkMByBV7LrTL5SOqulwPabpNE_
"""

! mkdir ~/.kaggle

with open("/content/kaggle.json","w") as f:
  f.write("""{"username":"bhargaveshdakka","key":"19f61f4a00c4dbc15ba24214d2d9dc77"}""")

!cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d ravirajsinh45/crop-and-weed-detection-data-with-bounding-boxes

import zipfile
zip_ref = zipfile.ZipFile('/content/crop-and-weed-detection-data-with-bounding-boxes.zip', 'r')
zip_ref.extractall("/content/")
zip_ref.close()

"""Packages"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import shutil

"""Splitting the data to their Respective directories"""

!rm -r /content/data

#seperating the data and image with two lists
!mkdir data
!mkdir data/crop
!mkdir data/weed

path = "/content/agri_data/data/"
for data_row in os.listdir(path):
  if data_row.split(".")[-1] == "txt":
    with open(path + data_row) as f:
      if f.read(1)=="0":
        shutil.copy(path+data_row, "/content/data/crop")
        shutil.copy(path +data_row.split(".")[0]+".jpeg", "/content/data/crop" )
      else:
        shutil.copy(path+data_row, "/content/data/crop")
        shutil.copy(path +data_row.split(".")[0]+".jpeg", "/content/data/weed")

len(os.listdir("/content/data/crop"))

len(os.listdir("/content/data/weed"))

len(os.listdir("/content/data/crop")) + len(os.listdir("/content/data/weed"))

len(os.listdir("/content/agri_data/data"))

"""Our data has splitted successfully we can crop the data according the text file."""

# checking whether splitted successfully
import matplotlib.pyplot as plt
import cv2

"""Crop - 0 Weed - 1"""

def crop_pic(pic_name):
  pic_name = str(pic_name).split(".")[0]
  image = plt.imread(pic_name+".jpeg")
  # plt.imshow(image)
  # Define the original image width and height
  W, H = int(image.shape[1]), int(image.shape[0])

  with open(pic_name+".txt", "r") as picture:
    data = picture.readline()
    data = data.split(" ")
  # Define the normalized bounding box coordinates
  normalized_x = pd.to_numeric(data[1])
  normalized_y = pd.to_numeric(data[2])
  normalized_width = pd.to_numeric(data[3])
  normalized_height = pd.to_numeric(data[4])
  # print(normalized_x, normalized_y, normalized_width, normalized_height )

  # Convert normalized coordinates to absolute coordinates
  X = normalized_x * W
  Y = normalized_y * H
  width = normalized_width * W
  height = normalized_height * H
  # print(X,Y, width, height)

  # Calculate the top-left and bottom-right coordinates of the bounding box
  x1 = int( X - (int(width) // 2))
  y1 = int( Y - (int(height) // 2))
  x2 = int( X + (int(width) // 2))
  y2 = int( Y + (int(height) // 2))
  # print(x1,x2, y1, y2)

  # Crop the image using the calculated coordinates
  cropped_image = image[y1:y2,  x1:x2]

  # Display the cropped image
  # plt.imshow(cropped_image)
  return cropped_image

for img in os.listdir(path = "/content/data/crop/"):

  if img.split(".")[1] == "jpeg":
    img_name = path + img
    # plt.imshow(plt.imread(img_name))
    cropped = crop_pic(img_name)
    plt.imsave(img_name,cropped)

image = plt.imread("/content/agri_data/data/agri_0_1026")
plt.imshow(image)

c = crop_pic("/content/data/crop/agri_0_1026.jpeg")
image = plt.imread(c)
plt.imshow(image)

#seperating the data and image with two lists
!mkdir cropped_data
!mkdir cropped_data/crop
!mkdir cropped_data/weed

path = "/content/agri_data/data/"
for data_row in os.listdir(path):
  if data_row.split(".")[-1] == "txt":
    with open(path + data_row) as f:
      if f.read(1)=="0":
        shutil.copy(path+data_row, "/content/cropped_data/crop")
        shutil.copy(path +data_row.split(".")[0]+".jpeg", "/content/cropped_data/crop" )
      else:
        shutil.copy(path+data_row, "/content/cropped_data/crop")
        shutil.copy(path +data_row.split(".")[0]+".jpeg", "/content/cropped_data/weed")

def crop_image(image_path):
  img = image_path.split(".")
  print("".join(img[:-1])+".jpeg")

plt.imshow(plt.imread(crop_image("/content/agri_data/data/agri_0_1009.jpeg")))

plt.imshow(plt.imread(path + image_data[10]))
with open(path+text_data[10], "r") as f:
  plt.title(f.read(1))

len(os.listdir("/content/crop")) + len(os.listdir("/content/weed"))

!mkdir data

shutil.move("/content/crop", "/content/data")
shutil.move("/content/weed", "/content/data")

from tensorflow.keras.utils import image_dataset_from_directory
import tensorflow as tf

train = image_dataset_from_directory(
    directory = '/content/data',
    labels='inferred',
    label_mode = 'int',
    batch_size=32,
    image_size=(512,512)
)

# Normalization
def process(image,label):
    image = tf.cast(image/255. ,tf.float32)
    return image,label

train_ds = train.map(process)

from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout

model = Sequential()

model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(512,512,3)))
model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(512,512,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))

model.add(Flatten())

model.add(Dense(128,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1,activation='sigmoid'))

model.summary()

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

history = model.fit(train_ds,epochs=5,verbose = 1)

plt.plot(history.history['accuracy'],color='red',label='train')
plt.show()

plt.plot(history.history['loss'],color='red',label='train')

"""validation"""

import cv2

image = cv2.imread("/content/data/crop/1000agri_0_4058.jpeg")

plt.imshow(image)

test_input = image.reshape((1,512,512,3))

model.predict(test_input)

text.loc[text["file_name"] == "agri_0_4058.txt"]

img = cv2.imread("/content/data/weed/100agri_0_2549.jpeg")



